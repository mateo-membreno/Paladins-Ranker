{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3 as sq\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "conn = sq.connect(\"../paladins.db\")\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM match\", conn)\n",
    "\n",
    "df[\"result\"] = df[\"result\"].apply(lambda x: 0 if x == 'L' else 1)\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"champion\"], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "champion_cols = [col for col in df.columns if col.startswith(\"champion_\")]\n",
    "agg_dict = {col: 'sum' for col in champion_cols}\n",
    "agg_dict.update({\"result\" : \"first\", \"match_id\" : \"first\"})\n",
    "\n",
    "df = df.groupby([\"match_id\", \"result\"], as_index=False).agg(agg_dict).reset_index()\n",
    "\n",
    "X = df[champion_cols]\n",
    "y = df[\"result\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateomembreno/Documents/Projects/Paladins-Ranker/env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "    layers.Dropout(0.3),                                            \n",
    "    layers.Dense(32, activation='relu'),                            \n",
    "    layers.Dense(1, activation='sigmoid')                            \n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6523 - loss: 0.6300 - val_accuracy: 0.5440 - val_loss: 0.7048\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6558 - loss: 0.6151 - val_accuracy: 0.5660 - val_loss: 0.7058\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6415 - loss: 0.6197 - val_accuracy: 0.5472 - val_loss: 0.7102\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6684 - loss: 0.6138 - val_accuracy: 0.5535 - val_loss: 0.7109\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6748 - loss: 0.5931 - val_accuracy: 0.5629 - val_loss: 0.7176\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7107 - loss: 0.5707 - val_accuracy: 0.5723 - val_loss: 0.7251\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7086 - loss: 0.5685 - val_accuracy: 0.5189 - val_loss: 0.7306\n",
      "Epoch 8/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7129 - loss: 0.5690 - val_accuracy: 0.5660 - val_loss: 0.7321\n",
      "Epoch 9/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7034 - loss: 0.5701 - val_accuracy: 0.5566 - val_loss: 0.7411\n",
      "Epoch 10/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6925 - loss: 0.5695 - val_accuracy: 0.5503 - val_loss: 0.7433\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.5638 - loss: 0.7511\n",
      "Test Accuracy: 0.55\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step\n",
      "Predict accuracy: [[0.56461394]\n",
      " [0.5076779 ]\n",
      " [0.67518926]\n",
      " [0.26261434]\n",
      " [0.29056743]\n",
      " [0.6379622 ]\n",
      " [0.6551038 ]\n",
      " [0.5201993 ]\n",
      " [0.35647598]\n",
      " [0.29690474]\n",
      " [0.3926794 ]\n",
      " [0.26988405]\n",
      " [0.25676453]\n",
      " [0.6850825 ]\n",
      " [0.48154017]\n",
      " [0.19106333]\n",
      " [0.8941721 ]\n",
      " [0.32798672]\n",
      " [0.45880517]\n",
      " [0.25237763]\n",
      " [0.65892345]\n",
      " [0.13678476]\n",
      " [0.7708526 ]\n",
      " [0.4145642 ]\n",
      " [0.25919637]\n",
      " [0.4726743 ]\n",
      " [0.61298406]\n",
      " [0.6666353 ]\n",
      " [0.97849274]\n",
      " [0.37330452]\n",
      " [0.7168182 ]\n",
      " [0.71264905]\n",
      " [0.8748422 ]\n",
      " [0.6277032 ]\n",
      " [0.55826485]\n",
      " [0.5851304 ]\n",
      " [0.1015057 ]\n",
      " [0.49691764]\n",
      " [0.64231193]\n",
      " [0.49235573]\n",
      " [0.23142833]\n",
      " [0.35954094]\n",
      " [0.4429115 ]\n",
      " [0.6400627 ]\n",
      " [0.03119909]\n",
      " [0.1636348 ]\n",
      " [0.3980195 ]\n",
      " [0.14806071]\n",
      " [0.40834117]\n",
      " [0.3724809 ]\n",
      " [0.7263394 ]\n",
      " [0.77866703]\n",
      " [0.25405946]\n",
      " [0.8608898 ]\n",
      " [0.3987167 ]\n",
      " [0.20776513]\n",
      " [0.13807872]\n",
      " [0.7214066 ]\n",
      " [0.4269978 ]\n",
      " [0.25479403]\n",
      " [0.79222995]\n",
      " [0.2518585 ]\n",
      " [0.45434687]\n",
      " [0.50640786]\n",
      " [0.367105  ]\n",
      " [0.395609  ]\n",
      " [0.4629642 ]\n",
      " [0.48028463]\n",
      " [0.42518312]\n",
      " [0.8278853 ]\n",
      " [0.43525815]\n",
      " [0.69094193]\n",
      " [0.27840728]\n",
      " [0.57026297]\n",
      " [0.4038627 ]\n",
      " [0.63622016]\n",
      " [0.16249514]\n",
      " [0.769163  ]\n",
      " [0.4610704 ]\n",
      " [0.52541184]\n",
      " [0.69665617]\n",
      " [0.63422805]\n",
      " [0.37229055]\n",
      " [0.5405745 ]\n",
      " [0.862263  ]\n",
      " [0.6176984 ]\n",
      " [0.82686293]\n",
      " [0.3863953 ]\n",
      " [0.35444364]\n",
      " [0.53836447]\n",
      " [0.18280324]\n",
      " [0.38656434]\n",
      " [0.7069076 ]\n",
      " [0.5485756 ]\n",
      " [0.17202605]\n",
      " [0.59868735]\n",
      " [0.7813143 ]\n",
      " [0.7381957 ]\n",
      " [0.39192167]\n",
      " [0.5218206 ]\n",
      " [0.19370137]\n",
      " [0.778349  ]\n",
      " [0.567834  ]\n",
      " [0.34705365]\n",
      " [0.5583843 ]\n",
      " [0.46800372]\n",
      " [0.33301356]\n",
      " [0.45759082]\n",
      " [0.60633045]\n",
      " [0.6880806 ]\n",
      " [0.461342  ]\n",
      " [0.74940413]\n",
      " [0.34560293]\n",
      " [0.7836334 ]\n",
      " [0.4073221 ]\n",
      " [0.5795648 ]\n",
      " [0.43027946]\n",
      " [0.43447605]\n",
      " [0.4045027 ]\n",
      " [0.8465344 ]\n",
      " [0.35238102]\n",
      " [0.46743795]\n",
      " [0.15512007]\n",
      " [0.36482203]\n",
      " [0.7489749 ]\n",
      " [0.56715024]\n",
      " [0.22643866]\n",
      " [0.9719031 ]\n",
      " [0.3349235 ]\n",
      " [0.7574172 ]\n",
      " [0.61864436]\n",
      " [0.46667957]\n",
      " [0.34816325]\n",
      " [0.63026106]\n",
      " [0.5619108 ]\n",
      " [0.20029894]\n",
      " [0.5563949 ]\n",
      " [0.44166976]\n",
      " [0.8130576 ]\n",
      " [0.65126735]\n",
      " [0.78738457]\n",
      " [0.37782043]\n",
      " [0.54937077]\n",
      " [0.63949174]\n",
      " [0.39649907]\n",
      " [0.25388393]\n",
      " [0.8925616 ]\n",
      " [0.4197316 ]\n",
      " [0.782604  ]\n",
      " [0.61792916]\n",
      " [0.56650865]\n",
      " [0.70062804]\n",
      " [0.47890583]\n",
      " [0.25238457]\n",
      " [0.31669733]\n",
      " [0.5384139 ]\n",
      " [0.5323363 ]\n",
      " [0.5800177 ]\n",
      " [0.3525267 ]\n",
      " [0.5117348 ]\n",
      " [0.7711102 ]\n",
      " [0.42240393]\n",
      " [0.52260596]\n",
      " [0.27040377]\n",
      " [0.3197327 ]\n",
      " [0.65171784]\n",
      " [0.80592763]\n",
      " [0.4823367 ]\n",
      " [0.6408486 ]\n",
      " [0.22692162]\n",
      " [0.28123263]\n",
      " [0.21400554]\n",
      " [0.57013446]\n",
      " [0.59661114]\n",
      " [0.51243234]\n",
      " [0.6759327 ]\n",
      " [0.42482707]\n",
      " [0.65607107]\n",
      " [0.19736859]\n",
      " [0.343634  ]\n",
      " [0.6381275 ]\n",
      " [0.6315833 ]\n",
      " [0.44668886]\n",
      " [0.54241455]\n",
      " [0.27142367]\n",
      " [0.3775234 ]\n",
      " [0.764425  ]\n",
      " [0.5704056 ]\n",
      " [0.8166227 ]\n",
      " [0.45807815]\n",
      " [0.35174385]\n",
      " [0.5202804 ]\n",
      " [0.777832  ]\n",
      " [0.7729812 ]\n",
      " [0.6511021 ]\n",
      " [0.57635313]\n",
      " [0.58221537]\n",
      " [0.3054459 ]\n",
      " [0.47034055]\n",
      " [0.68642145]\n",
      " [0.26458856]\n",
      " [0.5713215 ]\n",
      " [0.43020687]\n",
      " [0.51154524]\n",
      " [0.24558114]\n",
      " [0.58193105]\n",
      " [0.44890323]\n",
      " [0.31006673]\n",
      " [0.41708118]\n",
      " [0.39588523]\n",
      " [0.6782657 ]\n",
      " [0.31692347]\n",
      " [0.2696622 ]\n",
      " [0.5713777 ]\n",
      " [0.6495087 ]\n",
      " [0.28313434]\n",
      " [0.5575942 ]\n",
      " [0.4243895 ]\n",
      " [0.41275513]\n",
      " [0.42619136]\n",
      " [0.4657937 ]\n",
      " [0.15853712]\n",
      " [0.4673291 ]\n",
      " [0.51207227]\n",
      " [0.40881953]\n",
      " [0.15365331]\n",
      " [0.71787775]\n",
      " [0.27880663]\n",
      " [0.38762182]\n",
      " [0.5201165 ]\n",
      " [0.42423227]\n",
      " [0.22924067]\n",
      " [0.5012772 ]\n",
      " [0.579879  ]\n",
      " [0.16268471]\n",
      " [0.7131216 ]\n",
      " [0.58312136]\n",
      " [0.42192286]\n",
      " [0.7965869 ]\n",
      " [0.5925576 ]\n",
      " [0.7469962 ]\n",
      " [0.43236572]\n",
      " [0.9739894 ]\n",
      " [0.50019884]\n",
      " [0.18467534]\n",
      " [0.4370765 ]\n",
      " [0.63953865]\n",
      " [0.7632409 ]\n",
      " [0.6821977 ]\n",
      " [0.8012487 ]\n",
      " [0.5968439 ]\n",
      " [0.6662271 ]\n",
      " [0.49625468]\n",
      " [0.652569  ]\n",
      " [0.47828403]\n",
      " [0.6586004 ]\n",
      " [0.626216  ]\n",
      " [0.635497  ]\n",
      " [0.7186917 ]\n",
      " [0.28408837]\n",
      " [0.7694702 ]\n",
      " [0.76320773]\n",
      " [0.50999767]\n",
      " [0.7072622 ]\n",
      " [0.6674973 ]\n",
      " [0.33640683]\n",
      " [0.66497433]\n",
      " [0.3178011 ]\n",
      " [0.7615279 ]\n",
      " [0.3288307 ]\n",
      " [0.12310705]\n",
      " [0.5845355 ]\n",
      " [0.4941591 ]\n",
      " [0.61481947]\n",
      " [0.6718183 ]\n",
      " [0.41614032]\n",
      " [0.3244792 ]\n",
      " [0.7606953 ]\n",
      " [0.86031216]\n",
      " [0.31871814]\n",
      " [0.80410945]\n",
      " [0.6656262 ]\n",
      " [0.60926175]\n",
      " [0.4822273 ]\n",
      " [0.56238204]\n",
      " [0.72195756]\n",
      " [0.5265316 ]\n",
      " [0.13236193]\n",
      " [0.4507904 ]\n",
      " [0.9461661 ]\n",
      " [0.80998355]\n",
      " [0.07116017]\n",
      " [0.525955  ]\n",
      " [0.706301  ]\n",
      " [0.27402633]\n",
      " [0.16472791]\n",
      " [0.35614944]\n",
      " [0.45308417]\n",
      " [0.52703613]\n",
      " [0.23075135]\n",
      " [0.48260826]\n",
      " [0.4122562 ]\n",
      " [0.2685554 ]\n",
      " [0.5880916 ]\n",
      " [0.70725316]\n",
      " [0.34517756]\n",
      " [0.39475772]\n",
      " [0.63562644]\n",
      " [0.21903767]\n",
      " [0.43813756]\n",
      " [0.7799425 ]\n",
      " [0.35171816]\n",
      " [0.6591643 ]\n",
      " [0.42299622]\n",
      " [0.37729648]\n",
      " [0.6375016 ]\n",
      " [0.21675722]\n",
      " [0.3162536 ]\n",
      " [0.60082245]\n",
      " [0.8808445 ]\n",
      " [0.7180063 ]\n",
      " [0.49859533]\n",
      " [0.35618225]\n",
      " [0.45417756]\n",
      " [0.8150039 ]\n",
      " [0.5632559 ]\n",
      " [0.6962432 ]\n",
      " [0.5918141 ]\n",
      " [0.5856609 ]\n",
      " [0.72015774]\n",
      " [0.69743073]\n",
      " [0.46522802]\n",
      " [0.68028307]\n",
      " [0.31406268]\n",
      " [0.21070573]\n",
      " [0.15321377]\n",
      " [0.56113994]\n",
      " [0.5030277 ]\n",
      " [0.6639893 ]\n",
      " [0.16755758]\n",
      " [0.8094097 ]\n",
      " [0.39622194]\n",
      " [0.5760991 ]\n",
      " [0.57997537]\n",
      " [0.39277533]\n",
      " [0.27425104]\n",
      " [0.15229487]\n",
      " [0.6850096 ]\n",
      " [0.7363471 ]\n",
      " [0.4115428 ]\n",
      " [0.48899826]\n",
      " [0.5982852 ]\n",
      " [0.5200954 ]\n",
      " [0.2757416 ]\n",
      " [0.5498003 ]\n",
      " [0.28998414]\n",
      " [0.35886928]\n",
      " [0.40221053]\n",
      " [0.6059892 ]\n",
      " [0.22523957]\n",
      " [0.5247051 ]\n",
      " [0.7954946 ]\n",
      " [0.43769377]\n",
      " [0.41989073]\n",
      " [0.6494047 ]\n",
      " [0.4102733 ]\n",
      " [0.39853144]\n",
      " [0.5479713 ]\n",
      " [0.40215123]\n",
      " [0.59957016]\n",
      " [0.606852  ]\n",
      " [0.71244067]\n",
      " [0.44503668]\n",
      " [0.4425931 ]\n",
      " [0.2872489 ]\n",
      " [0.5587178 ]\n",
      " [0.24114285]\n",
      " [0.6673096 ]\n",
      " [0.7137961 ]\n",
      " [0.39534646]\n",
      " [0.47281703]\n",
      " [0.222536  ]\n",
      " [0.5764914 ]\n",
      " [0.44531435]\n",
      " [0.51260495]\n",
      " [0.9945387 ]\n",
      " [0.22672743]\n",
      " [0.33255154]\n",
      " [0.33977953]\n",
      " [0.24765162]\n",
      " [0.5543874 ]\n",
      " [0.46505463]\n",
      " [0.7006104 ]\n",
      " [0.27739024]\n",
      " [0.33195853]\n",
      " [0.28731745]\n",
      " [0.41599724]\n",
      " [0.79077667]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_binary_crossentropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredict accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_pred_proba\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_binary_crossentropy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(val_loss)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),val_loss)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_binary_crossentropy'"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=32, \n",
    "                    validation_split=0.2, \n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "print(f\"Predict accuracy: {y_pred_proba}\")\n",
    "\n",
    "val_loss = history.history[\"val_binary_crossentropy\"]\n",
    "plt.plot(np.arange(1,len(val_loss)+1),val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
